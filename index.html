<!DOCTYPE html>
<html>
<head>
    <title>My First Website</title>
</head>
<body>
    <h1>Gpu</h1>
    <p>

WikipediaThe Free Encyclopedia
Search Wikipedia
Search
Donate
Create account
Log in
Contents hide
(Top)
History

1970s
1980s
1990s
2000s
2010s
2020s
GPU companies
Computational functions

2D graphics APIs
GPU forms

Terminology
Dedicated graphics processing unit
Integrated graphics processing unit
Stream processing and general purpose GPUs (GPGPU)
External GPU (eGPU)
Energy efficiency
Sales
See also

Hardware
APIs
Applications
References
Sources
External links
Graphics processing unit

Article
Talk
Read
Edit
View history

Tools
Appearance hide
Text

Small

Standard

Large
Width

Standard

Wide
Color (beta)

Automatic

Light

Dark
From Wikipedia, the free encyclopedia
"GPU" redirects here. For other uses, see GPU (disambiguation).
For an expansion card that contains a graphics processing unit, see Graphics card.

Components of a GPU
A graphics processing unit (GPU) is a specialized electronic circuit designed for digital image processing and to accelerate computer graphics, being present either as a component on a discrete graphics card or embedded on motherboards, mobile phones, personal computers, workstations, and game consoles. GPUs are increasingly being used for AI processing due to linear algebra acceleration which is also used extensively in graphics processing.

Although there is no single definition of the term, and it may be used to describe any video display system, in modern use a GPU includes the ability to internally perform the calculations needed for various graphics tasks, like rotating and scaling 3D images, and often the additional ability to run custom programs known as shaders. This contrasts with earlier graphics controllers known as video display controllers which had no internal calculation capabilities, or blitters, which performed only basic memory movement operations. The modern GPU emerged during the 1990s, adding the ability to perform operations like drawing lines and text without CPU help, and later adding 3D functionality.

Graphics functions are generally independent and this lends these tasks to being implemented on separate calculation engines. Modern GPUs include hundreds, or thousands, of calculation units. This made them useful for non-graphic calculations involving embarrassingly parallel problems due to their parallel structure. The ability of GPUs to rapidly perform vast numbers of calculations has led to their adoption in diverse fields including artificial intelligence (AI) where they excel at handling data-intensive and computationally demanding tasks. Other non-graphical uses include the training of neural networks and cryptocurrency mining.

History
See also: Video display controller, List of home computers by video hardware, and Sprite (computer graphics)
1970s
Arcade system boards have used specialized graphics circuits since the 1970s. In early video game hardware, RAM for frame buffers was expensive, so video chips composited data together as the display was being scanned out on the monitor.[1]

A specialized barrel shifter circuit helped the CPU animate the framebuffer graphics for various 1970s arcade video games from Midway and Taito, such as Gun Fight (1975), Sea Wolf (1976), and Space Invaders (1978).[2] The Namco Galaxian arcade system in 1979 used specialized graphics hardware that supported RGB color, multi-colored sprites, and tilemap backgrounds.[3] The Galaxian hardware was widely used during the golden age of arcade video games, by game companies such as Namco, Centuri, Gremlin, Irem, Konami, Midway, Nichibutsu, Sega, and Taito.[4]


Atari ANTIC microprocessor on an Atari 130XE motherboard
The Atari 2600 in 1977 used a video shifter called the Television Interface Adaptor.[5] Atari 8-bit computers (1979) had ANTIC, a video processor which interpreted instructions describing a "display list"—the way the scan lines map to specific bitmapped or character modes and where the memory is stored (so there did not need to be a contiguous frame buffer).[clarification needed][6] 6502 machine code subroutines could be triggered on scan lines by setting a bit on a display list instruction.[clarification needed][7] ANTIC also supported smooth vertical and horizontal scrolling independent of the CPU.[8]

1980s

NEC μPD7220A
The NEC μPD7220 was the first implementation of a personal computer graphics display processor as a single large-scale integration (LSI) integrated circuit chip. This enabled the design of low-cost, high-performance video graphics cards such as those from Number Nine Visual Technology. It became the best-known GPU until the mid-1980s.[9] It was the first fully integrated VLSI (very large-scale integration) metal–oxide–semiconductor (NMOS) graphics display processor for PCs, supported up to 1024×1024 resolution, and laid the foundations for the PC graphics market. It was used in a number of graphics cards and was licensed for clones such as the Intel 82720, the first of Intel's graphics processing units.[10] The Williams Electronics arcade games Robotron: 2084, Joust, Sinistar, and Bubbles, all released in 1982, contain custom blitter chips for operating on 16-color bitmaps.[11][12]

In 1984, Hitachi released the ARTC HD63484, the first major CMOS graphics processor for personal computers. The ARTC could display up to 4K resolution when in monochrome mode. It was used in a number of graphics cards and terminals during the late 1980s.[13] In 1985, the Amiga was released with a custom graphics chip including a blitter for bitmap manipulation, line drawing, and area fill. It also included a coprocessor with its own simple instruction set, that was capable of manipulating graphics hardware registers in sync with the video beam (e.g. for per-scanline palette switches, sprite multiplexing, and hardware windowing), or driving the blitter. In 1986, Texas Instruments released the TMS34010, the first fully programmable graphics processor.[14] It could run general-purpose code but also had a graphics-oriented instruction set. During 1990–1992, this chip became the basis of the Texas Instruments Graphics Architecture ("TIGA") Windows accelerator cards.


The IBM 8514 Micro Channel adapter, with memory add-on
In 1987, the IBM 8514 graphics system was released. It was one of the first video cards for IBM PC compatibles that implemented fixed-function 2D primitives in electronic hardware. Sharp's X68000, released in 1987, used a custom graphics chipset[15] with a 65,536 color palette and hardware support for sprites, scrolling, and multiple playfields.[16] It served as a development machine for Capcom's CP System arcade board. Fujitsu's FM Towns computer, released in 1989, had support for a 16,777,216 color palette.[17] In 1988, the first dedicated polygonal 3D graphics boards were introduced in arcades with the Namco System 21[18] and Taito Air System.[19]


VGA section on the motherboard in IBM PS/55
IBM introduced its proprietary Video Graphics Array (VGA) display standard in 1987, with a maximum resolution of 640×480 pixels. In November 1988, NEC Home Electronics announced its creation of the Video Electronics Standards Association (VESA) to develop and promote a Super VGA (SVGA) computer display standard as a successor to VGA. Super VGA enabled graphics display resolutions up to 800×600 pixels, a 56% increase.[20]

1990s 

Tseng Labs ET4000/W32p

S3 Graphics ViRGE

Voodoo3 2000 AGP card
In 1991, S3 Graphics introduced the S3 86C911, which its designers named after the Porsche 911 as an indication of the performance increase it promised.[21] The 86C911 spawned a variety of imitators: by 1995, all major PC graphics chip makers had added 2D acceleration support to their chips.[22] Fixed-function Windows accelerators surpassed expensive general-purpose graphics coprocessors in Windows performance, and such coprocessors faded from the PC market.

In the early- and mid-1990s, real-time 3D graphics became increasingly common in arcade, computer, and console games, which led to increasing public demand for hardware-accelerated 3D graphics. Early examples of mass-market 3D graphics hardware can be found in arcade system boards such as the Sega Model 1, Namco System 22, and Sega Model 2, and the fifth-generation video game consoles such as the Saturn, PlayStation, and Nintendo 64. Arcade systems such as the Sega Model 2 and SGI Onyx-based Namco Magic Edge Hornet Simulator in 1993 were capable of hardware T&L (transform, clipping, and lighting) years before appearing in consumer graphics cards.[23][24] Another early example is the Super FX chip, a RISC-based on-cartridge graphics chip used in some SNES games, notably Doom and Star Fox. Some systems used DSPs to accelerate transformations. Fujitsu, which worked on the Sega Model 2 arcade system,[25] began working on integrating T&L into a single LSI solution for use in home computers in 1995;[26] the Fujitsu Pinolite, the first 3D geometry processor for personal computers, announced in 1997.[27] The first hardware T&L GPU on home video game consoles was the Nintendo 64's Reality Coprocessor, released in 1996.[28] In 1997, Mitsubishi released the 3Dpro/2MP, a GPU capable of transformation and lighting, for workstations and Windows NT desktops;[29] ATi used it for its FireGL 4000 graphics card, released in 1997.[30]

The term "GPU" was coined by Sony in reference to the 32-bit Sony GPU (designed by Toshiba) in the PlayStation video game console, released in 1994.[31]

2000s
In October 2002, with the introduction of the ATI Radeon 9700 (also known as R300), the world's first Direct3D 9.0 accelerator, pixel and vertex shaders could implement looping and lengthy floating point math, and were quickly becoming as flexible as CPUs, yet orders of magnitude faster for image-array operations. Pixel shading is often used for bump mapping, which adds texture to make an object look shiny, dull, rough, or even round or extruded.[32]

With the introduction of the Nvidia GeForce 8 series and new generic stream processing units, GPUs became more generalized computing devices. Parallel GPUs are making computational inroads against the CPU, and a subfield of research, dubbed GPU computing or GPGPU for general purpose computing on GPU, has found applications in fields as diverse as machine learning,[33] oil exploration, scientific image processing, linear algebra,[34] statistics,[35] 3D reconstruction, and stock options pricing. GPGPUs were the precursors to what is now called a compute shader (e.g. CUDA, OpenCL, DirectCompute) and actually abused the hardware to a degree by treating the data passed to algorithms as texture maps and executing algorithms by drawing a triangle or quad with an appropriate pixel shader.[clarification needed] This entails some overheads since units like the scan converter are involved where they are not needed (nor are triangle manipulations even a concern—except to invoke the pixel shader).[clarification needed]

Nvidia's CUDA platform, first introduced in 2007,[36] was the earliest widely adopted programming model for GPU computing. OpenCL is an open standard defined by the Khronos Group that allows for the development of code for both GPUs and CPUs with an emphasis on portability.[37] OpenCL solutions are supported by Intel, AMD, Nvidia, and ARM, and according to a report in 2011 by Evans Data, OpenCL had become the second most popular HPC tool.[38]

2010s
In 2010, Nvidia partnered with Audi to power their cars' dashboards, using the Tegra GPU to provide increased functionality to cars' navigation and entertainment systems.[39] Advances in GPU technology in cars helped advance self-driving technology.[40] AMD's Radeon HD 6000 series cards were released in 2010, and in 2011 AMD released its 6000M Series discrete GPUs for mobile devices.[41] The Kepler line of graphics cards by Nvidia were released in 2012 and were used in the Nvidia 600 and 700 series cards. A feature in this GPU microarchitecture included GPU boost, a technology that adjusts the clock-speed of a video card to increase or decrease according to its power draw.[42] Kepler also introduced NVENC video encoding acceleration technology.

The PS4 and Xbox One were released in 2013; they both used GPUs based on AMD's Radeon HD 7850 and 7790.[43] Nvidia's Kepler line of GPUs was followed by the Maxwell line, manufactured on the same process. Nvidia's 28 nm chips were manufactured by TSMC in Taiwan using the 28 nm process. Compared to the 40 nm technology from the past, this manufacturing process allowed a 20 percent boost in performance while drawing less power.[44][45] Virtual reality headsets have high system requirements; manufacturers recommended the GTX 970 and the R9 290X or better at the time of their release.[46][47] Cards based on the Pascal microarchitecture were released in 2016. The GeForce 10 series of cards are of this generation of graphics cards. They are made using the 16 nm manufacturing process which improves upon previous microarchitectures.[48]

In 2018, Nvidia launched the RTX 20 series GPUs that added ray tracing cores to GPUs, improving their performance on lighting effects.[49] Polaris 11 and Polaris 10 GPUs from AMD are fabricated by a 14 nm process. Their release resulted in a substantial increase in the performance per watt of AMD video cards.[50] AMD also released the Vega GPU series for the high end market as a competitor to Nvidia's high end Pascal cards, also featuring HBM2 like the Titan V.

In 2019, AMD released the successor to their Graphics Core Next (GCN) microarchitecture/instruction set. Dubbed RDNA, the first product featuring it was the Radeon RX 5000 series of video cards.[51] The company announced that the successor to the RDNA microarchitecture would be incremental (a "refresh"). AMD unveiled the Radeon RX 6000 series, its RDNA 2 graphics cards with support for hardware-accelerated ray tracing.[52] The product series, launched in late 2020, consisted of the RX 6800, RX 6800 XT, and RX 6900 XT.[53][54] The RX 6700 XT, which is based on Navi 22, was launched in early 2021.[55]

The PlayStation 5 and Xbox Series X and Series S were released in 2020; they both use GPUs based on the RDNA 2 microarchitecture with incremental improvements and different GPU configurations in each system's implementation.[56][57][58]

2020s
See also: AI accelerator
In the 2020s, GPUs have been increasingly used for calculations involving embarrassingly parallel problems, such as training of neural networks on enormous datasets that are needed for artificial intelligence large language models. Specialized processing cores on some modern workstation's GPUs are dedicated for deep learning since they have significant FLOPS performance increases, using 4×4 matrix multiplication and division, resulting in hardware performance up to 128 TFLOPS in some applications.[59] These tensor cores are expected to appear in consumer cards, as well.[needs update][60]

GPU companies
Many companies have produced GPUs under a number of brand names. In 2009,[needs update] Intel, Nvidia, and AMD/ATI were the market share leaders, with 49.4%, 27.8%, and 20.6% market share respectively. In addition, Matrox[61] produces GPUs. Chinese companies such as Jingjia Micro have also produced GPUs for the domestic market although in terms of worldwide sales, they lag behind market leaders.[62]

Computational functions
Several factors of GPU construction affect the performance of the card for real-time rendering, such as the size of the connector pathways in the semiconductor device fabrication, the clock signal frequency, and the number and size of various on-chip memory caches. Performance is also affected by the number of streaming multiprocessors (SM) for NVidia GPUs, or compute units (CU) for AMD GPUs, or Xe cores for Intel Xe based GPUs, which describe the number of on-silicon processor core units within the GPU chip that perform the core calculations, typically working in parallel with other SM/CUs on the GPU. GPU performance is typically measured in floating point operations per second (FLOPS); GPUs in the 2010s and 2020s typically deliver performance measured in teraflops (TFLOPS). This is an estimated performance measure, as other factors can affect the actual display rate.[63]


The ATI HD5470 GPU (above, with copper heatpipe attached) features UVD 2.1 which enables it to decode AVC and VC-1 video formats.
2D graphics APIs
An earlier GPU may support one or more 2D graphics APIs for 2D acceleration, such as GDI and DirectDraw.[64]

GPU forms
Terminology
In the 1970s, the term "GPU" originally stood for graphics processor unit and described a programmable processing unit working independently from the CPU that was responsible for graphics manipulation and output.[65][66] In 1994, Sony used the term (now standing for graphics processing unit) in reference to the PlayStation console's Toshiba-designed Sony GPU.[31] The term was popularized by Nvidia in 1999, who marketed the GeForce 256 as "the world's first GPU".[67] It was presented as a "single-chip processor with integrated transform, lighting, triangle setup/clipping, and rendering engines".[68] Rival ATI Technologies coined the term "visual processing unit" or VPU with the release of the Radeon 9700 in 2002.[69] The AMD Alveo MA35D features dual VPU’s, each using the 5 nm process in 2023.[70]

In personal computers, there are two main forms of GPUs. Each has many synonyms:[71]

Dedicated graphics also called discrete graphics.
Integrated graphics also called shared graphics solutions, integrated graphics processors (IGP), or unified memory architecture (UMA).
Dedicated graphics processing unit
See also: Video card
Dedicated graphics processing units use RAM that is dedicated to the GPU rather than relying on the computer’s main system memory. This RAM is usually specially selected for the expected serial workload of the graphics card (see GDDR). Sometimes systems with dedicated discrete GPUs were called "DIS" systems as opposed to "UMA" systems (see next section).[72]

Technologies such as Scan-Line Interleave by 3dfx, SLI and NVLink by Nvidia and CrossFire by AMD allow multiple GPUs to draw images simultaneously for a single screen, increasing the processing power available for graphics. These technologies, however, are increasingly uncommon; most games do not fully use multiple GPUs, as most users cannot afford them.[73][74][75] Multiple GPUs are still used on supercomputers (like in Summit), on workstations to accelerate video (processing multiple videos at once)[76][77][78] and 3D rendering,[79] for VFX,[80] GPGPU workloads and for simulations,[81] and in AI to expedite training, as is the case with Nvidia's lineup of DGX workstations and servers, Tesla GPUs, and Intel's Ponte Vecchio GPUs.

Integrated graphics processing unit

The position of an integrated GPU in a northbridge/southbridge system layout

An ASRock motherboard with integrated graphics, which has HDMI, VGA and DVI-out ports
Integrated graphics processing units (IGPU), integrated graphics, shared graphics solutions, integrated graphics processors (IGP), or unified memory architectures (UMA) use a portion of a computer's system RAM rather than dedicated graphics memory. IGPs can be integrated onto a motherboard as part of its northbridge chipset,[82] or on the same die (integrated circuit) with the CPU (like AMD APU or Intel HD Graphics). On certain motherboards,[83] AMD's IGPs can use dedicated sideport memory: a separate fixed block of high performance memory that is dedicated for use by the GPU. As of early 2007, computers with integrated graphics account for about 90% of all PC shipments.[84][needs update] They are less costly to implement than dedicated graphics processing, but tend to be less capable. Historically, integrated processing was considered unfit for 3D games or graphically intensive programs but could run less intensive programs such as Adobe Flash. Examples of such IGPs would be offerings from SiS and VIA circa 2004.[85] However, modern integrated graphics processors such as AMD Accelerated Processing Unit and Intel Graphics Technology (HD, UHD, Iris, Iris Pro, Iris Plus, and Xe-LP) can handle 2D graphics or low-stress 3D graphics.

Since GPU computations are memory-intensive, integrated processing may compete with the CPU for relatively slow system RAM, as it has minimal or no dedicated video memory. IGPs use system memory with bandwidth up to a current maximum of 128 GB/s, whereas a discrete graphics card may have a bandwidth[86] of more than 1000 GB/s between its VRAM and GPU core. This memory bus bandwidth can limit the performance of the GPU, though multi-channel memory can mitigate this deficiency.[87] Older integrated graphics chipsets lacked hardware transform and lighting, but newer ones include it.[88][89]

On systems with "Unified Memory Architecture" (UMA), including modern AMD processors with integrated graphics,[90] modern Intel processors with integrated graphics,[91] Apple processors, the PS5 and Xbox Series (among others), the CPU cores and the GPU block share the same pool of RAM and memory address space.

Stream processing and general purpose GPUs (GPGPU)
Main articles: GPGPU and Stream processing
It is common to use a general purpose graphics processing unit (GPGPU) as a modified form of stream processor (or a vector processor), running compute kernels. This turns the massive computational power of a modern graphics accelerator's shader pipeline into general-purpose computing power. In certain applications requiring massive vector operations, this can yield several orders of magnitude higher performance than a conventional CPU. The two largest discrete (see "Dedicated graphics processing unit" above) GPU designers, AMD and Nvidia, are pursuing this approach with an array of applications. Both Nvidia and AMD teamed with Stanford University to create a GPU-based client for the Folding@home distributed computing project for protein folding calculations. In certain circumstances, the GPU calculates forty times faster than the CPUs traditionally used by such applications.[92][93]

GPU-based high performance computers play a significant role in large-scale modelling. Three of the ten most powerful supercomputers in the world take advantage of GPU acceleration.[94]

Since 2005 there has been interest in using the performance offered by GPUs for evolutionary computation in general, and for accelerating the fitness evaluation in genetic programming in particular. Most approaches compile linear or tree programs on the host PC and transfer the executable to the GPU to be run. Typically a performance advantage is only obtained by running the single active program simultaneously on many example problems in parallel, using the GPU's SIMD architecture.[95] However, substantial acceleration can also be obtained by not compiling the programs, and instead transferring them to the GPU, to be interpreted there.[96]

External GPU (eGPU)
Therefore, it is desirable to attach a GPU to some external bus of a notebook. PCI Express is the only bus used for this purpose. The port may be, for example, an ExpressCard or mPCIe port (PCIe ×1, up to 5 or 2.5 Gbit/s respectively), a Thunderbolt 1, 2, or 3 port (PCIe ×4, up to 10, 20, or 40 Gbit/s respectively), a USB4 port with Thunderbolt compatibility, or an OCuLink port. Those ports are only available on certain notebook systems.[97] eGPU enclosures include their own power supply (PSU), because powerful GPUs can consume hundreds of watts.[98]

Energy efficiency
This section is an excerpt from Performance per watt § GPU efficiency.[edit]
Graphics processing units (GPU) have continued to increase in energy usage, while CPUs designers have recently[when?] focused on improving performance per watt. High performance GPUs may draw large amount of power, therefore intelligent techniques are required to manage GPU power consumption. Measures like 3DMark2006 score per watt can help identify more efficient GPUs.[99] However that may not adequately incorporate efficiency in typical use, where much time is spent doing less demanding tasks.[100]

With modern GPUs, energy usage is an important constraint on the maximum computational capabilities that can be achieved. GPU designs are usually highly scalable, allowing the manufacturer to put multiple chips on the same video card, or to use multiple video cards that work in parallel. Peak performance of any system is essentially limited by the amount of power it can draw and the amount of heat it can dissipate. Consequently, performance per watt of a GPU design translates directly into peak performance of a system that uses that design.

Since GPUs may also be used for some general purpose computation, sometimes their performance is measured in terms also applied to CPUs, such as FLOPS per watt.

Sales
In 2013, 438.3 million GPUs were shipped globally and the forecast for 2014 was 414.2 million. However, by the third quarter of 2022, shipments of PC GPUs totaled around 75.5 million units, down 19% year-over-year.[101][needs update][102]

See also
UALink
Texture mapping unit (TMU)
Render output unit (ROP)
Brute force attack
Computer hardware
Computer monitor
GPU cache
GPU virtualization
Manycore processor
Physics processing unit (PPU)
Tensor processing unit (TPU)
Ray-tracing hardware
Single instruction, multiple threads (SIMT))
Software rendering
Vision processing unit (VPU)
Vector processor
Video card
Video display controller
Video game console
AI accelerator
GPU Vector Processor internal features
Hardware
List of AMD graphics processing units
List of Nvidia graphics processing units
List of Intel graphics processing units
List of discrete and integrated graphics processing units
Intel GMA
Larrabee
Nvidia PureVideo – the bit-stream technology from Nvidia used in their graphics chips to accelerate video decoding on hardware GPU with DXVA.
SoC
UVD (Unified Video Decoder) – the video decoding bit-stream technology from ATI to support hardware (GPU) decode with DXVA
APIs
OpenGL API
OpenCL API
OpenVX API
TensorFlow Lite
Mantle (API)
Metal (API)
Core ML
Vulkan (API)
Direct3D
DirectX Video Acceleration (DxVA) API for Microsoft Windows operating-system.
DirectML
Direct2D
DirectDraw
DirectWrite
Video Acceleration API (VA API)
VDPAU (Video Decode and Presentation API for Unix)
X-Video Bitstream Acceleration (XvBA), the X11 equivalent of DXVA for MPEG-2, H.264, and VC-1
X-Video Motion Compensation – the X11 equivalent for MPEG-2 video codec only
Applications
GPU cluster
Mathematica – includes built-in support for CUDA and OpenCL GPU execution
Molecular modeling on GPU
Deeplearning4j – open-source, distributed deep learning for Java
References
 Hague, James (September 10, 2013). "Why Do Dedicated Game Consoles Exist?". Programming in the 21st Century. Archived from the original on May 4, 2015. Retrieved November 11, 2015.
 "mame/8080bw.c at master 路 mamedev/mame 路 GitHub". GitHub. Archived from the original on 2014-11-21.
"mame/mw8080bw.c at master 路 mamedev/mame 路 GitHub". GitHub. Archived from the original on 2014-11-21.
"Arcade/SpaceInvaders – Computer Archeology". computerarcheology.com. Archived from the original on 2014-09-13.
 "mame/galaxian.c at master 路 mamedev/mame 路 GitHub". GitHub. Archived from the original on 2014-11-21.
 "mame/galaxian.c at master 路 mamedev/mame 路 GitHub". GitHub. Archived from the original on 2014-11-21.
"MAME – src/mame/drivers/galdrvr.c". Archived from the original on 3 January 2014.
 Springmann, Alessondra. "Atari 2600 Teardown: What?s Inside Your Old Console?". The Washington Post. Archived from the original on July 14, 2015. Retrieved July 14, 2015.
 "What are the 6502, ANTIC, CTIA/GTIA, POKEY, and FREDDIE chips?". Atari8.com. Archived from the original on 2016-03-05.
 Wiegers, Karl E. (April 1984). "Atari Display List Interrupts". Compute! (47): 161. Archived from the original on 2016-03-04.
 Wiegers, Karl E. (December 1985). "Atari Fine Scrolling". Compute! (67): 110. Archived from the original on 2006-02-16.
 Hopgood, F. Robert A.; Hubbold, Roger J.; Duce, David A., eds. (1986). Advances in Computer Graphics II. Springer. p. 169. ISBN 9783540169109. Perhaps the best known one is the NEC 7220.
 Anderson, Marian (2018-07-18). "Famous Graphics Chips: NEC μPD7220 Graphics Display Controller". IEEE Computer Society. Retrieved 2023-10-17.
 Riddle, Sean. "Blitter Information". Archived from the original on 2015-12-22.
 Wolf, Mark J. P. (June 2012). Before the Crash: Early Video Game History. Wayne State University Press. p. 185. ISBN 978-0814337226.
 Anderson, Marian (2018-10-07). "GPU History: Hitachi ARTC HD63484". IEEE Computer Society. Retrieved 2023-10-17.
 "Famous Graphics Chips: TI TMS34010 and VRAM. The first programmable graphics processor chip | IEEE Computer Society". 10 January 2019.
 "X68000". Archived from the original on 2014-09-03. Retrieved 2014-09-12.
 "museum ~ Sharp X68000". Old-computers.com. Archived from the original on 2015-02-19. Retrieved 2015-01-28.
 "Hardcore Gaming 101: Retro Japanese Computers: Gaming's Final Frontier". hardcoregaming101.net. Archived from the original on 2011-01-13.
 "System 16 – Namco System 21 Hardware (Namco)". system16.com. Archived from the original on 2015-05-18.
 "System 16 – Taito Air System Hardware (Taito)". system16.com. Archived from the original on 2015-03-16.
 Brownstein, Mark (November 14, 1988). "NEC Forms Video Standards Group". InfoWorld. Vol. 10, no. 46. p. 3. ISSN 0199-6649. Retrieved May 27, 2016.
 "S3 Video Boards". InfoWorld. 14 (20): 62. May 18, 1992. Archived from the original on November 22, 2017. Retrieved July 13, 2015.
 "What the numbers mean". PC Magazine. 12: 128. 23 February 1993. Archived from the original on 11 April 2017. Retrieved 29 March 2016.
Singer, Graham. "The History of the Modern Graphics Processor". Techspot. Archived from the original on 29 March 2016. Retrieved 29 March 2016.
 "System 16 – Namco Magic Edge Hornet Simulator Hardware (Namco)". system16.com. Archived from the original on 2014-09-12.
 "MAME – src/mame/video/model2.c". Archived from the original on 4 January 2013.
 "System 16 – Sega Model 2 Hardware (Sega)". system16.com. Archived from the original on 2010-12-21.
 "3D Graphics Processor Chip Set" (PDF). Archived from the original (PDF) on 2016-10-11. Retrieved 2016-08-08.
"3D-CG System with Video Texturing for Personal Computers" (PDF). Archived from the original (PDF) on 2014-09-06. Retrieved 2016-08-08.
 "Fujitsu Develops World's First Three Dimensional Geometry Processor". fujitsu.com. Archived from the original on 2014-09-12.
 "The Nintendo 64 is one of the greatest gaming devices of all time". xenol. Archived from the original on 2015-11-18.
 "Mitsubishi's 3DPro/2mp Chipset Sets New Records for Fastest 3D Graphics Accelerator for Windows NT Systems; 3DPro/2mp grabs Viewperf performance lead; other high-end benchmark tests clearly show that 3DPro's performance outdistances all Windows NT competitors". Archived from the original on 2018-11-15. Retrieved 2022-02-18.
 Vlask. "VGA Legacy MKIII – Diamond Fire GL 4000 (Mitsubishi 3DPro/2mp)". Archived from the original on 2015-11-18.
 "Is it Time to Rename the GPU? | IEEE Computer Society". 17 July 2018.
 Dreijer, Søren. "Bump Mapping Using CG (3rd Edition)". Archived from the original on 2010-01-20. Retrieved 2007-05-30.
 Raina, Rajat; Madhavan, Anand; Ng, Andrew Y. (2009-06-14). "Large-scale deep unsupervised learning using graphics processors". Proceedings of the 26th Annual International Conference on Machine Learning – ICML '09. Dl.acm.org. pp. 1–8. doi:10.1145/1553374.1553486. ISBN 9781605585161. S2CID 392458.
 "Linear algebra operators for GPU implementation of numerical algorithms", Kruger and Westermann, International Conference on Computer Graphics and Interactive Techniques, 2005
 Liepe; et al. (2010). "ABC-SysBio—approximate Bayesian computation in Python with GPU support". Bioinformatics. 26 (14): 1797–1799. doi:10.1093/bioinformatics/btq278. PMC 2894518. PMID 20591907. Archived from the original on 2015-11-05. Retrieved 2010-10-15.
 Sanders, Jason; Kandrot, Edward (2010-07-19). CUDA by Example: An Introduction to General-Purpose GPU Programming, Portable Documents. Addison-Wesley Professional. ISBN 9780132180139. Archived from the original on 2017-04-12.
 "OpenCL – The open standard for parallel programming of heterogeneous systems". khronos.org. Archived from the original on 2011-08-09.
 Handy, Alex (2011-09-28). "AMD helps OpenCL gain ground in HPC space". SD Times. Retrieved 2023-06-04.
 Teglet, Traian (8 January 2010). "NVIDIA Tegra Inside Every Audi 2010 Vehicle". Archived from the original on 2016-10-04. Retrieved 2016-08-03.
 "School's in session – Nvidia's driverless system learns by watching". 2016-04-30. Archived from the original on 2016-05-01. Retrieved 2016-08-03.
 "AMD Radeon HD 6000M series – don't call it ATI!". CNET. Archived from the original on 2016-10-11. Retrieved 2016-08-03.
 "Nvidia GeForce GTX 680 2GB Review". Archived from the original on 2016-09-11. Retrieved 2016-08-03.
 "Xbox One vs. PlayStation 4: Which game console is best?". ExtremeTech. 20 November 2015. Retrieved 2019-05-13.
 "Kepler TM GK110" (PDF). NVIDIA Corporation. 2012. Archived (PDF) from the original on October 11, 2016. Retrieved August 3, 2016.
 "Taiwan Semiconductor Manufacturing Company Limited". www.tsmc.com. Archived from the original on 2016-08-10. Retrieved 2016-08-03.
 "Building a PC for the HTC Vive". 2016-06-16. Archived from the original on 2016-07-29. Retrieved 2016-08-03.
 "VIVE Ready Computers". Vive. Archived from the original on 2016-02-24. Retrieved 2021-07-30.
 "Nvidia's monstrous Pascal GPU is packed with cutting-edge tech and 15 billion transistors". 5 April 2016. Archived from the original on 2016-07-31. Retrieved 2016-08-03.
 Sarkar, Samit (20 August 2018). "Nvidia RTX 2070, RTX 2080, RTX 2080 Ti GPUs revealed: specs, price, release date". Polygon. Retrieved 11 September 2019.
 "AMD RX 480, 470 & 460 Polaris GPUs To Deliver The 'Most Revolutionary Jump In Performance' Yet". 2016-01-16. Archived from the original on 2016-08-01. Retrieved 2016-08-03.
 AMD press release: "AMD Announces Next-Generation Leadership Products at Computex 2019 Keynote". AMD. Retrieved October 5, 2019.
 "AMD to Introduce New Next-Gen RDNA GPUs in 2020, Not a Typical 'Refresh' of Navi". Tom's Hardware. 2020-01-29. Retrieved 2020-02-08.
Garreffa, Anthony (September 9, 2020). "AMD to reveal next-gen Big Navi RDNA 2 graphics cards on October 28". TweakTown. Retrieved September 9, 2020.
Lyles, Taylor (September 9, 2020). "AMD's next-generation Zen 3 CPUs and Radeon RX 6000 'Big Navi' GPU will be revealed next month". The Verge. Retrieved September 10, 2020.
 "AMD Teases Radeon RX 6000 Card Performance Numbers: Aiming For 3080?". AnandTech. 2020-10-08. Archived from the original on 2020-10-08. Retrieved 2020-10-25.
"AMD Announces Ryzen 'Zen 3' and Radeon 'RDNA2' Presentations for October: A New Journey Begins". AnandTech. 2020-09-09. Archived from the original on 2020-09-10. Retrieved 2020-10-25.
 Judd, Will (October 28, 2020). "AMD unveils three Radeon 6000 graphics cards with ray tracing and RTX-beating performance". Eurogamer. Retrieved October 28, 2020.
 Mujtaba, Hassan (2020-11-30). "AMD Radeon RX 6700 XT 'Navi 22 GPU' Custom Models Reportedly Boost Up To 2.95 GHz". Wccftech. Retrieved 2020-12-03.
Tyson, Mark (December 3, 2020). "AMD CEO keynote scheduled for CES 2020 on 12th January". HEXUS. Retrieved 2020-12-03.
Cutress, Ian (January 12, 2021). "AMD to Launch Mid-Range RDNA 2 Desktop Graphics in First Half 2021". AnandTech. Archived from the original on January 12, 2021. Retrieved January 4, 2021.
 Funk, Ben (December 12, 2020). "Sony PS5 Gets A Full Teardown Detailing Its RDNA 2 Guts And Glory". Hot Hardware. Archived from the original on December 12, 2020. Retrieved January 3, 2021.
 Gartenberg, Chaim (March 18, 2020). "Sony reveals full PS5 hardware specifications". The Verge. Retrieved January 3, 2021.
 Smith, Ryan. "Microsoft Drops More Xbox Series X Tech Specs: Zen 2 + RDNA 2, 12 TFLOPs GPU, HDMI 2.1, & a Custom SSD". AnandTech. Archived from the original on February 24, 2020. Retrieved 2020-03-19.
 Smith, Ryan. "NVIDIA Volta Unveiled: GV100 GPU and Tesla V100 Accelerator Announced". AnandTech. Archived from the original on May 11, 2017. Retrieved 16 August 2018.
 Hill, Brandon (11 August 2017). "AMD's Navi 7nm GPU Architecture to Reportedly Feature Dedicated AI Circuitry". HotHardware. Archived from the original on 17 August 2018. Retrieved 16 August 2018.
 "Matrox Graphics – Products – Graphics Cards". Matrox.com. Archived from the original on 2014-02-05. Retrieved 2014-01-21.
 Pan, Che (31 July 2023). "Blacklisted Jingjia Micro to develop GPUs in Wuxi in latest chip self sufficiency move". South China Morning Post. Retrieved 20 January 2025.
 Hruska, Joel (February 10, 2021). "How Do Graphics Cards Work?". Extreme Tech. Retrieved July 17, 2021.
 CL-GD5446 64-bit VisualMedia Accelerator Preliminary Data Book (PDF), Cirrus Logic, November 1996, retrieved 30 January 2024 – via The Datasheet Archive
 Barron, E. T.; Glorioso, R. M. (September 1973). "A micro controlled peripheral processor". Conference record of the 6th annual workshop on Microprogramming – MICRO 6. pp. 122–128. doi:10.1145/800203.806247. ISBN 9781450377836. S2CID 36942876.
 Levine, Ken (August 1978). "Core standard graphic package for the VGI 3400". ACM SIGGRAPH Computer Graphics. 12 (3): 298–300. doi:10.1145/965139.807405.
 "NVIDIA Launches the World's First Graphics Processing Unit: GeForce 256". Nvidia. 31 August 1999. Archived from the original on 12 April 2016. Retrieved 28 March 2016.
 "Graphics Processing Unit (GPU)". Nvidia. 16 December 2009. Archived from the original on 8 April 2016. Retrieved 29 March 2016.
 Pabst, Thomas (18 July 2002). "ATi Takes Over 3D Technology Leadership With Radeon 9700". Tom's Hardware. Retrieved 29 March 2016.
 Child, J. (6 April 2023). "AMD Rolls Out 5 nm ASIC-based Accelerator for the Interactive Streaming Era". EETech Media. Retrieved 24 December 2023.
 "Help Me Choose: Video Cards". Dell. Archived from the original on 2016-09-09. Retrieved 2016-09-17.
 "Nvidia Optimus documentation for Linux device driver". freedesktop. 13 November 2023. Retrieved 24 December 2023.
 Abazovic, F. (3 July 2015). "Crossfire and SLI market is just 300.000 units". fudzilla. Retrieved 24 December 2023.
 "Is Multi-GPU Dead?". 7 January 2018.
 "Nvidia SLI and AMD CrossFire is dead – but should we mourn multi-GPU gaming? | TechRadar". 24 August 2019.
 "NVIDIA FFmpeg Transcoding Guide". 24 July 2019.
 "Hardware Selection and Configuration Guide DaVinci Resolve 15" (PDF). BlackMagic Design. 2018. Retrieved 31 May 2022.
 "Recommended System: Recommended Systems for DaVinci Resolve". Puget Systems.
"GPU Accelerated Rendering and Hardware Encoding".
 "V-Ray Next Multi-GPU Performance Scaling". 20 August 2019.
"FAQ | GPU-accelerated 3D rendering software | Redshift". Archived from the original on 2020-04-11. Retrieved 2020-03-03.
"OctaneRender 2020™ Preview is here!". Otoy.
"Exploring Performance with Autodesk's Arnold Renderer GPU Beta". 8 April 2019.
"GPU Rendering – Blender Manual".
 "V-Ray for Nuke – Ray Traced Rendering for Compositors | Chaos Group".
"System Requirements | Nuke | Foundry".
 "What about multi-GPU support? – Folding@home".
 "Evolution of Intel Graphics: I740 to Iris Pro". 4 February 2017.
 "GA-890GPA-UD3H overview". Archived from the original on 2015-04-15. Retrieved 2015-04-15.
 Key, Gary. "AnandTech – μATX Part 2: Intel G33 Performance Review". anandtech.com. Archived from the original on 2008-05-31.
 Tscheblockov, Tim. "Xbit Labs: Roundup of 7 Contemporary Integrated Graphics Chipsets for Socket 478 and Socket A Platforms". Archived from the original on 2007-05-26. Retrieved 2007-06-03.
 "GPU Memory Bandwidth Evolution 2007-2025: NVIDIA AMD Intel". Axiom Gaming. Retrieved 17 August 2025.
 Coelho, Rafael (18 January 2016). "Does dual-channel memory make difference on integrated video performance?". Hardware Secrets. Retrieved 4 January 2019.
 Sanford, Bradley. "Integrated Graphics Solutions for Graphics-Intensive Applications" (PDF). Archived (PDF) from the original on 2007-11-28. Retrieved 2007-09-02.
 Sanford, Bradley. "Integrated Graphics Solutions for Graphics-Intensive Applications". Archived from the original on 2012-01-07. Retrieved 2007-09-02.
 Shimpi, Anand Lal. "AMD Outlines HSA Roadmap: Unified Memory for CPU/GPU in 2013, HSA GPUs in 2014". www.anandtech.com. Archived from the original on February 4, 2012. Retrieved 2024-01-08.
 Lake, Adam T. "Getting the Most from OpenCL™ 1.2: How to Increase Performance by..." Intel. Retrieved 2024-01-08.
 Murph, Darren (29 September 2006). "Stanford University tailors Folding@home to GPUs". Archived from the original on 2007-10-12. Retrieved 2007-10-04.
 Houston, Mike. "Folding@Home – GPGPU". Archived from the original on 2007-10-27. Retrieved 2007-10-04.
 "Top500 List – June 2012 | TOP500 Supercomputer Sites". Top500.org. Archived from the original on 2014-01-13. Retrieved 2014-01-21.
 Nickolls, John (July 2008). "Stanford Lecture: Scalable Parallel Programming with CUDA on Manycore GPUs". YouTube. Archived from the original on 2016-10-11.
Harding, S.; Banzhaf, W. "Fast genetic programming on GPUs". Archived from the original on 2008-06-09. Retrieved 2008-05-01.
 Langdon, W.; Banzhaf, W. "A SIMD interpreter for Genetic Programming on GPU Graphics Cards". Archived from the original on 2008-06-09. Retrieved 2008-05-01.
V. Garcia and E. Debreuve and M. Barlaud. Fast k nearest neighbor search using GPU. In Proceedings of the CVPR Workshop on Computer Vision on GPU, Anchorage, Alaska, USA, June 2008.
 Mohr, Neil. "How to make an external laptop graphics adaptor". TechRadar. Archived from the original on 2017-06-26.
 "Best External Graphics Card 2020 (EGPU) [The Complete Guide]". 16 March 2020.
 Atwood, Jeff (2006-08-18). "Video Card Power Consumption". Archived from the original on 8 September 2008. Retrieved 26 March 2008.
 "Video card power consumption". Xbit Labs. Archived from the original on 2011-09-04.
 "GPU Q3'22 biggest quarter-to-quarter drop since the 2009 recession". Jon Peddie Research. 2022-11-20. Retrieved 2023-06-06.
 "Graphics chips market is showing some life". TG Daily. August 20, 2014. Archived from the original on August 26, 2014. Retrieved August 22, 2014.
Sources
Peddie, Jon (1 January 2023). The History of the GPU – New Developments. Springer Nature. ISBN 978-3-03-114047-1. OCLC 1356877844.
External links

Wikimedia Commons has media related to Graphics processing units.
NVIDIA – What is GPU computing?
The GPU Gems book series
– A Graphics Hardware History Archived 2022-03-31 at the Wayback Machine[dead link]
How GPUs work
GPU Caps Viewer – Video card information utility
ARM Mali GPUs Overview
Authority control databases Edit this at Wikidata
vte
Graphics processing unit
vte
Hardware acceleration
Categories: Graphics processing unitsGPGPU librariesGraphics hardwareVirtual realityOpenCL compute devicesArtificial intelligenceApplication-specific integrated circuitsHardware accelerationDigital electronicsElectronic designElectronic design automation
This page was last edited on 29 December 2025, at 08:34 (UTC).
Text is available under the Creative Commons Attribution-ShareAlike 4.0 License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.
Privacy policyAbout WikipediaDisclaimersContact WikipediaLegal & safety contactsCode of ConductDevelopersStatisticsCookie statementMobile view
Wikimedia Foundation
Powered by MediaWiki
In computer graphics, the render output unit or raster operations pipeline (ROP) is a hardware component in modern graphics processing units (GPUs) and one of the final steps in the rendering process of modern graphics cards. The pixel pipelines take pixel and texel information and process it, via specific matrix and vector operations, into a final pixel or depth value; this process is called rasterization. Thus, ROPs control antialiasing, when more than one sample is merged into one pixel. The ROPs perform the transactions between the relevant buffers in the local memory – this includes writing or reading values, as well as blending them together. Dedicated antialiasing hardware used to perform hardware-based antialiasing methods like MSAA is contained in ROPs.

</p>
</body>
</html>
<!DOCTYPE html>
<html>
<head>
    <title>My First Website</title>
    <style>
        body {
            background-color: #f0f8ff; /* light blue background */
            font-family: Arial, sans-serif;
            text-align: center;
            padding: 50px;
        }
        h1 {
            color: #ff4500; /* orange */
        }
        p {
            color: #333333;
            font-size: 18px;
        }
    </style>
</head>
<body>
    <h1>This is my first webpage!</h1>
    <p>Give me tips on my discord!</p>
</body>
</html>
<button onclick="sayHello()">Citations!</button>

<script>
function sayHello() {
    alert("Wikipedia");
}
</script>
<!DOCTYPE html>
<html>
<head>
    <title>Blue Background</title>
    <style>
        body {
            background-color: #a8d0e6; /* soft blue background */
            margin: 0; /* removes default spacing around the page */
            height: 100vh; /* makes background fill the whole screen */
        }
    </style>
</head>
<body>
</body>
</html>

